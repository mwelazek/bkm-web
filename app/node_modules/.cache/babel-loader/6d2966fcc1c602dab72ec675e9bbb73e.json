{"ast":null,"code":"//\n\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n// This implementation of {@link TokenStream} loads tokens from a\n// {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n// access to any previous token by index.\n//\n// <p>\n// This token stream ignores the value of {@link Token//getChannel}. If your\n// parser requires the token stream filter tokens to only those on a particular\n// channel, such as {@link Token//DEFAULT_CHANNEL} or\n// {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n// {@link CommonTokenStream}.</p>\nvar Token = require('./Token').Token;\n\nvar Lexer = require('./Lexer').Lexer;\n\nvar Interval = require('./IntervalSet').Interval; // this is just to keep meaningful parameter types to Parser\n\n\nfunction TokenStream() {\n  return this;\n}\n\nfunction BufferedTokenStream(tokenSource) {\n  TokenStream.call(this); // The {@link TokenSource} from which tokens for this stream are fetched.\n\n  this.tokenSource = tokenSource; // A collection of all tokens fetched from the token source. The list is\n  // considered a complete view of the input once {@link //fetchedEOF} is set\n  // to {@code true}.\n\n  this.tokens = []; // The index into {@link //tokens} of the current token (next token to\n  // {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n  // be\n  // {@link //LT LT(1)}.\n  //\n  // <p>This field is set to -1 when the stream is first constructed or when\n  // {@link //setTokenSource} is called, indicating that the first token has\n  // not yet been fetched from the token source. For additional information,\n  // see the documentation of {@link IntStream} for a description of\n  // Initializing Methods.</p>\n\n  this.index = -1; // Indicates whether the {@link Token//EOF} token has been fetched from\n  // {@link //tokenSource} and added to {@link //tokens}. This field improves\n  // performance for the following cases:\n  //\n  // <ul>\n  // <li>{@link //consume}: The lookahead check in {@link //consume} to\n  // prevent\n  // consuming the EOF symbol is optimized by checking the values of\n  // {@link //fetchedEOF} and {@link //p} instead of calling {@link\n  // //LA}.</li>\n  // <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n  // into\n  // {@link //tokens} is trivial with this field.</li>\n  // <ul>\n\n  this.fetchedEOF = false;\n  return this;\n}\n\nBufferedTokenStream.prototype = Object.create(TokenStream.prototype);\nBufferedTokenStream.prototype.constructor = BufferedTokenStream;\n\nBufferedTokenStream.prototype.mark = function () {\n  return 0;\n};\n\nBufferedTokenStream.prototype.release = function (marker) {// no resources to release\n};\n\nBufferedTokenStream.prototype.reset = function () {\n  this.seek(0);\n};\n\nBufferedTokenStream.prototype.seek = function (index) {\n  this.lazyInit();\n  this.index = this.adjustSeekIndex(index);\n};\n\nBufferedTokenStream.prototype.get = function (index) {\n  this.lazyInit();\n  return this.tokens[index];\n};\n\nBufferedTokenStream.prototype.consume = function () {\n  var skipEofCheck = false;\n\n  if (this.index >= 0) {\n    if (this.fetchedEOF) {\n      // the last token in tokens is EOF. skip check if p indexes any\n      // fetched token except the last.\n      skipEofCheck = this.index < this.tokens.length - 1;\n    } else {\n      // no EOF token in tokens. skip check if p indexes a fetched token.\n      skipEofCheck = this.index < this.tokens.length;\n    }\n  } else {\n    // not yet initialized\n    skipEofCheck = false;\n  }\n\n  if (!skipEofCheck && this.LA(1) === Token.EOF) {\n    throw \"cannot consume EOF\";\n  }\n\n  if (this.sync(this.index + 1)) {\n    this.index = this.adjustSeekIndex(this.index + 1);\n  }\n}; // Make sure index {@code i} in tokens has a token.\n//\n// @return {@code true} if a token is located at index {@code i}, otherwise\n// {@code false}.\n// @see //get(int i)\n// /\n\n\nBufferedTokenStream.prototype.sync = function (i) {\n  var n = i - this.tokens.length + 1; // how many more elements we need?\n\n  if (n > 0) {\n    var fetched = this.fetch(n);\n    return fetched >= n;\n  }\n\n  return true;\n}; // Add {@code n} elements to buffer.\n//\n// @return The actual number of elements added to the buffer.\n// /\n\n\nBufferedTokenStream.prototype.fetch = function (n) {\n  if (this.fetchedEOF) {\n    return 0;\n  }\n\n  for (var i = 0; i < n; i++) {\n    var t = this.tokenSource.nextToken();\n    t.tokenIndex = this.tokens.length;\n    this.tokens.push(t);\n\n    if (t.type === Token.EOF) {\n      this.fetchedEOF = true;\n      return i + 1;\n    }\n  }\n\n  return n;\n}; // Get all tokens from start..stop inclusively///\n\n\nBufferedTokenStream.prototype.getTokens = function (start, stop, types) {\n  if (types === undefined) {\n    types = null;\n  }\n\n  if (start < 0 || stop < 0) {\n    return null;\n  }\n\n  this.lazyInit();\n  var subset = [];\n\n  if (stop >= this.tokens.length) {\n    stop = this.tokens.length - 1;\n  }\n\n  for (var i = start; i < stop; i++) {\n    var t = this.tokens[i];\n\n    if (t.type === Token.EOF) {\n      break;\n    }\n\n    if (types === null || types.contains(t.type)) {\n      subset.push(t);\n    }\n  }\n\n  return subset;\n};\n\nBufferedTokenStream.prototype.LA = function (i) {\n  return this.LT(i).type;\n};\n\nBufferedTokenStream.prototype.LB = function (k) {\n  if (this.index - k < 0) {\n    return null;\n  }\n\n  return this.tokens[this.index - k];\n};\n\nBufferedTokenStream.prototype.LT = function (k) {\n  this.lazyInit();\n\n  if (k === 0) {\n    return null;\n  }\n\n  if (k < 0) {\n    return this.LB(-k);\n  }\n\n  var i = this.index + k - 1;\n  this.sync(i);\n\n  if (i >= this.tokens.length) {\n    // return EOF token\n    // EOF must be last token\n    return this.tokens[this.tokens.length - 1];\n  }\n\n  return this.tokens[i];\n}; // Allowed derived classes to modify the behavior of operations which change\n// the current stream position by adjusting the target token index of a seek\n// operation. The default implementation simply returns {@code i}. If an\n// exception is thrown in this method, the current stream index should not be\n// changed.\n//\n// <p>For example, {@link CommonTokenStream} overrides this method to ensure\n// that\n// the seek target is always an on-channel token.</p>\n//\n// @param i The target token index.\n// @return The adjusted target token index.\n\n\nBufferedTokenStream.prototype.adjustSeekIndex = function (i) {\n  return i;\n};\n\nBufferedTokenStream.prototype.lazyInit = function () {\n  if (this.index === -1) {\n    this.setup();\n  }\n};\n\nBufferedTokenStream.prototype.setup = function () {\n  this.sync(0);\n  this.index = this.adjustSeekIndex(0);\n}; // Reset this token stream by setting its token source.///\n\n\nBufferedTokenStream.prototype.setTokenSource = function (tokenSource) {\n  this.tokenSource = tokenSource;\n  this.tokens = [];\n  this.index = -1;\n  this.fetchedEOF = false;\n}; // Given a starting index, return the index of the next token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and EOF.\n// /\n\n\nBufferedTokenStream.prototype.nextTokenOnChannel = function (i, channel) {\n  this.sync(i);\n\n  if (i >= this.tokens.length) {\n    return -1;\n  }\n\n  var token = this.tokens[i];\n\n  while (token.channel !== this.channel) {\n    if (token.type === Token.EOF) {\n      return -1;\n    }\n\n    i += 1;\n    this.sync(i);\n    token = this.tokens[i];\n  }\n\n  return i;\n}; // Given a starting index, return the index of the previous token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and 0.\n\n\nBufferedTokenStream.prototype.previousTokenOnChannel = function (i, channel) {\n  while (i >= 0 && this.tokens[i].channel !== channel) {\n    i -= 1;\n  }\n\n  return i;\n}; // Collect all tokens on specified channel to the right of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n// EOF. If channel is -1, find any non default channel token.\n\n\nBufferedTokenStream.prototype.getHiddenTokensToRight = function (tokenIndex, channel) {\n  if (channel === undefined) {\n    channel = -1;\n  }\n\n  this.lazyInit();\n\n  if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n    throw \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n  }\n\n  var nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n  var from_ = tokenIndex + 1; // if none onchannel to right, nextOnChannel=-1 so set to = last token\n\n  var to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n  return this.filterForChannel(from_, to, channel);\n}; // Collect all tokens on specified channel to the left of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n// If channel is -1, find any non default channel token.\n\n\nBufferedTokenStream.prototype.getHiddenTokensToLeft = function (tokenIndex, channel) {\n  if (channel === undefined) {\n    channel = -1;\n  }\n\n  this.lazyInit();\n\n  if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n    throw \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n  }\n\n  var prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\n  if (prevOnChannel === tokenIndex - 1) {\n    return null;\n  } // if none on channel to left, prevOnChannel=-1 then from=0\n\n\n  var from_ = prevOnChannel + 1;\n  var to = tokenIndex - 1;\n  return this.filterForChannel(from_, to, channel);\n};\n\nBufferedTokenStream.prototype.filterForChannel = function (left, right, channel) {\n  var hidden = [];\n\n  for (var i = left; i < right + 1; i++) {\n    var t = this.tokens[i];\n\n    if (channel === -1) {\n      if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n        hidden.push(t);\n      }\n    } else if (t.channel === channel) {\n      hidden.push(t);\n    }\n  }\n\n  if (hidden.length === 0) {\n    return null;\n  }\n\n  return hidden;\n};\n\nBufferedTokenStream.prototype.getSourceName = function () {\n  return this.tokenSource.getSourceName();\n}; // Get the text of all tokens in this buffer.///\n\n\nBufferedTokenStream.prototype.getText = function (interval) {\n  this.lazyInit();\n  this.fill();\n\n  if (interval === undefined || interval === null) {\n    interval = new Interval(0, this.tokens.length - 1);\n  }\n\n  var start = interval.start;\n\n  if (start instanceof Token) {\n    start = start.tokenIndex;\n  }\n\n  var stop = interval.stop;\n\n  if (stop instanceof Token) {\n    stop = stop.tokenIndex;\n  }\n\n  if (start === null || stop === null || start < 0 || stop < 0) {\n    return \"\";\n  }\n\n  if (stop >= this.tokens.length) {\n    stop = this.tokens.length - 1;\n  }\n\n  var s = \"\";\n\n  for (var i = start; i < stop + 1; i++) {\n    var t = this.tokens[i];\n\n    if (t.type === Token.EOF) {\n      break;\n    }\n\n    s = s + t.text;\n  }\n\n  return s;\n}; // Get all tokens from lexer until EOF///\n\n\nBufferedTokenStream.prototype.fill = function () {\n  this.lazyInit();\n\n  while (this.fetch(1000) === 1000) {\n    continue;\n  }\n};\n\nexports.BufferedTokenStream = BufferedTokenStream;","map":null,"metadata":{},"sourceType":"script"}