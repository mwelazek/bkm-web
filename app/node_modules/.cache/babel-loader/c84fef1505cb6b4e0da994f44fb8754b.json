{"ast":null,"code":"/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n// A lexer is recognizer that draws input symbols from a character stream.\n//  lexer grammars result in a subclass of this object. A Lexer object\n//  uses simplified match() and error recovery mechanisms in the interest of speed.\nvar Token = require('./Token').Token;\n\nvar Recognizer = require('./Recognizer').Recognizer;\n\nvar CommonTokenFactory = require('./CommonTokenFactory').CommonTokenFactory;\n\nvar RecognitionException = require('./error/Errors').RecognitionException;\n\nvar LexerNoViableAltException = require('./error/Errors').LexerNoViableAltException;\n\nfunction TokenSource() {\n  return this;\n}\n\nfunction Lexer(input) {\n  Recognizer.call(this);\n  this._input = input;\n  this._factory = CommonTokenFactory.DEFAULT;\n  this._tokenFactorySourcePair = [this, input];\n  this._interp = null; // child classes must populate this\n  // The goal of all lexer rules/methods is to create a token object.\n  // this is an instance variable as multiple rules may collaborate to\n  // create a single token. nextToken will return this object after\n  // matching lexer rule(s). If you subclass to allow multiple token\n  // emissions, then set this to the last token to be matched or\n  // something nonnull so that the auto token emit mechanism will not\n  // emit another token.\n\n  this._token = null; // What character index in the stream did the current token start at?\n  // Needed, for example, to get the text for current token. Set at\n  // the start of nextToken.\n\n  this._tokenStartCharIndex = -1; // The line on which the first character of the token resides///\n\n  this._tokenStartLine = -1; // The character position of first character within the line///\n\n  this._tokenStartColumn = -1; // Once we see EOF on char stream, next token will be EOF.\n  // If you have DONE : EOF ; then you see DONE EOF.\n\n  this._hitEOF = false; // The channel number for the current token///\n\n  this._channel = Token.DEFAULT_CHANNEL; // The token type for the current token///\n\n  this._type = Token.INVALID_TYPE;\n  this._modeStack = [];\n  this._mode = Lexer.DEFAULT_MODE; // You can set the text for the current token to override what is in\n  // the input char buffer. Use setText() or can set this instance var.\n  // /\n\n  this._text = null;\n  return this;\n}\n\nLexer.prototype = Object.create(Recognizer.prototype);\nLexer.prototype.constructor = Lexer;\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\nLexer.prototype.reset = function () {\n  // wack Lexer state variables\n  if (this._input !== null) {\n    this._input.seek(0); // rewind the input\n\n  }\n\n  this._token = null;\n  this._type = Token.INVALID_TYPE;\n  this._channel = Token.DEFAULT_CHANNEL;\n  this._tokenStartCharIndex = -1;\n  this._tokenStartColumn = -1;\n  this._tokenStartLine = -1;\n  this._text = null;\n  this._hitEOF = false;\n  this._mode = Lexer.DEFAULT_MODE;\n  this._modeStack = [];\n\n  this._interp.reset();\n}; // Return a token from this source; i.e., match a token on the char stream.\n\n\nLexer.prototype.nextToken = function () {\n  if (this._input === null) {\n    throw \"nextToken requires a non-null input stream.\";\n  } // Mark start location in char stream so unbuffered streams are\n  // guaranteed at least have text of current token\n\n\n  var tokenStartMarker = this._input.mark();\n\n  try {\n    while (true) {\n      if (this._hitEOF) {\n        this.emitEOF();\n        return this._token;\n      }\n\n      this._token = null;\n      this._channel = Token.DEFAULT_CHANNEL;\n      this._tokenStartCharIndex = this._input.index;\n      this._tokenStartColumn = this._interp.column;\n      this._tokenStartLine = this._interp.line;\n      this._text = null;\n      var continueOuter = false;\n\n      while (true) {\n        this._type = Token.INVALID_TYPE;\n        var ttype = Lexer.SKIP;\n\n        try {\n          ttype = this._interp.match(this._input, this._mode);\n        } catch (e) {\n          if (e instanceof RecognitionException) {\n            this.notifyListeners(e); // report error\n\n            this.recover(e);\n          } else {\n            console.log(e.stack);\n            throw e;\n          }\n        }\n\n        if (this._input.LA(1) === Token.EOF) {\n          this._hitEOF = true;\n        }\n\n        if (this._type === Token.INVALID_TYPE) {\n          this._type = ttype;\n        }\n\n        if (this._type === Lexer.SKIP) {\n          continueOuter = true;\n          break;\n        }\n\n        if (this._type !== Lexer.MORE) {\n          break;\n        }\n      }\n\n      if (continueOuter) {\n        continue;\n      }\n\n      if (this._token === null) {\n        this.emit();\n      }\n\n      return this._token;\n    }\n  } finally {\n    // make sure we release marker after match or\n    // unbuffered char stream will keep buffering\n    this._input.release(tokenStartMarker);\n  }\n}; // Instruct the lexer to skip creating a token for current lexer rule\n// and look for another token. nextToken() knows to keep looking when\n// a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n// if token==null at end of any token rule, it creates one for you\n// and emits it.\n// /\n\n\nLexer.prototype.skip = function () {\n  this._type = Lexer.SKIP;\n};\n\nLexer.prototype.more = function () {\n  this._type = Lexer.MORE;\n};\n\nLexer.prototype.mode = function (m) {\n  this._mode = m;\n};\n\nLexer.prototype.pushMode = function (m) {\n  if (this._interp.debug) {\n    console.log(\"pushMode \" + m);\n  }\n\n  this._modeStack.push(this._mode);\n\n  this.mode(m);\n};\n\nLexer.prototype.popMode = function () {\n  if (this._modeStack.length === 0) {\n    throw \"Empty Stack\";\n  }\n\n  if (this._interp.debug) {\n    console.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n  }\n\n  this.mode(this._modeStack.pop());\n  return this._mode;\n}; // Set the char stream and reset the lexer\n\n\nObject.defineProperty(Lexer.prototype, \"inputStream\", {\n  get: function () {\n    return this._input;\n  },\n  set: function (input) {\n    this._input = null;\n    this._tokenFactorySourcePair = [this, this._input];\n    this.reset();\n    this._input = input;\n    this._tokenFactorySourcePair = [this, this._input];\n  }\n});\nObject.defineProperty(Lexer.prototype, \"sourceName\", {\n  get: function sourceName() {\n    return this._input.sourceName;\n  }\n}); // By default does not support multiple emits per nextToken invocation\n// for efficiency reasons. Subclass and override this method, nextToken,\n// and getToken (to push tokens into a list and pull from that list\n// rather than a single variable as this implementation does).\n// /\n\nLexer.prototype.emitToken = function (token) {\n  this._token = token;\n}; // The standard method called to automatically emit a token at the\n// outermost lexical rule. The token object should point into the\n// char buffer start..stop. If there is a text override in 'text',\n// use that to set the token's text. Override this method to emit\n// custom Token objects or provide a new factory.\n// /\n\n\nLexer.prototype.emit = function () {\n  var t = this._factory.create(this._tokenFactorySourcePair, this._type, this._text, this._channel, this._tokenStartCharIndex, this.getCharIndex() - 1, this._tokenStartLine, this._tokenStartColumn);\n\n  this.emitToken(t);\n  return t;\n};\n\nLexer.prototype.emitEOF = function () {\n  var cpos = this.column;\n  var lpos = this.line;\n\n  var eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF, null, Token.DEFAULT_CHANNEL, this._input.index, this._input.index - 1, lpos, cpos);\n\n  this.emitToken(eof);\n  return eof;\n};\n\nObject.defineProperty(Lexer.prototype, \"type\", {\n  get: function () {\n    return this.type;\n  },\n  set: function (type) {\n    this._type = type;\n  }\n});\nObject.defineProperty(Lexer.prototype, \"line\", {\n  get: function () {\n    return this._interp.line;\n  },\n  set: function (line) {\n    this._interp.line = line;\n  }\n});\nObject.defineProperty(Lexer.prototype, \"column\", {\n  get: function () {\n    return this._interp.column;\n  },\n  set: function (column) {\n    this._interp.column = column;\n  }\n}); // What is the index of the current character of lookahead?///\n\nLexer.prototype.getCharIndex = function () {\n  return this._input.index;\n}; // Return the text matched so far for the current token or any text override.\n//Set the complete text of this token; it wipes any previous changes to the text.\n\n\nObject.defineProperty(Lexer.prototype, \"text\", {\n  get: function () {\n    if (this._text !== null) {\n      return this._text;\n    } else {\n      return this._interp.getText(this._input);\n    }\n  },\n  set: function (text) {\n    this._text = text;\n  }\n}); // Return a list of all Token objects in input char stream.\n// Forces load of all tokens. Does not include EOF token.\n// /\n\nLexer.prototype.getAllTokens = function () {\n  var tokens = [];\n  var t = this.nextToken();\n\n  while (t.type !== Token.EOF) {\n    tokens.push(t);\n    t = this.nextToken();\n  }\n\n  return tokens;\n};\n\nLexer.prototype.notifyListeners = function (e) {\n  var start = this._tokenStartCharIndex;\n  var stop = this._input.index;\n\n  var text = this._input.getText(start, stop);\n\n  var msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n  var listener = this.getErrorListenerDispatch();\n  listener.syntaxError(this, null, this._tokenStartLine, this._tokenStartColumn, msg, e);\n};\n\nLexer.prototype.getErrorDisplay = function (s) {\n  var d = [];\n\n  for (var i = 0; i < s.length; i++) {\n    d.push(s[i]);\n  }\n\n  return d.join('');\n};\n\nLexer.prototype.getErrorDisplayForChar = function (c) {\n  if (c.charCodeAt(0) === Token.EOF) {\n    return \"<EOF>\";\n  } else if (c === '\\n') {\n    return \"\\\\n\";\n  } else if (c === '\\t') {\n    return \"\\\\t\";\n  } else if (c === '\\r') {\n    return \"\\\\r\";\n  } else {\n    return c;\n  }\n};\n\nLexer.prototype.getCharErrorDisplay = function (c) {\n  return \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n}; // Lexers can normally match any char in it's vocabulary after matching\n// a token, so do the easy thing and just kill a character and hope\n// it all works out. You can instead use the rule invocation stack\n// to do sophisticated error recovery if you are in a fragment rule.\n// /\n\n\nLexer.prototype.recover = function (re) {\n  if (this._input.LA(1) !== Token.EOF) {\n    if (re instanceof LexerNoViableAltException) {\n      // skip a char and try again\n      this._interp.consume(this._input);\n    } else {\n      // TODO: Do we lose character or line position information?\n      this._input.consume();\n    }\n  }\n};\n\nexports.Lexer = Lexer;","map":null,"metadata":{},"sourceType":"script"}